{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#!{sys.executable} -m pip install opencv-python\n",
    "\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras_metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, GridSearchCV, validation_curve \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, r2_score, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, validation_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from tensorflow.keras import get_default_graph\n",
    "\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# This code has been tested with TensorFlow 1.6\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data path\n",
    "test_folder = '../../data/split/test'\n",
    "train_folder = '../../data/split/train'\n",
    "val_folder = '../../data/split/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68 images belonging to 11 classes.\n",
      "Found 261 images belonging to 11 classes.\n",
      "Found 870 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prep data for processing\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, shuffle=True,\n",
    "        target_size=(256,256), batch_size = batch_size) \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, shuffle=True,\n",
    "        target_size=(256,256), batch_size = batch_size)\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, shuffle=True,\n",
    "        target_size=(256,256), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (870,1))\n",
    "test_y = np.reshape(test_labels[:,0], (68,1))\n",
    "val_y = np.reshape(val_labels[:,0], (261,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ae58f01d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(val_y, color='red')\n",
    "sns.distplot(train_y, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 254, 254, 1024)    28672     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 127, 127, 1024)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 127, 127, 512)     4719104   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 63, 63, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 63, 63, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 31, 31, 64)        147520    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 11)                158411    \n",
      "=================================================================\n",
      "Total params: 6,233,611\n",
      "Trainable params: 6,233,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 783 samples, validate on 87 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(1024, (3, 3), activation='relu',input_shape=(256 ,256,  3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "# model.add(layers.Dropout(0.05))  \n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu', padding=\"same\"))\n",
    "#model.add(layers.Conv2D(256, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "# model.add(layers.Dropout(0.05))  \n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding=\"same\"))\n",
    "#model.add(layers.Conv2D(512, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Dropout(0.0025)) \n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "#model.add(layers.Conv2D(512, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Dropout(0.0025)) \n",
    "\n",
    "#model.add(layers.Dense(256, activation='sigmoid'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_labels,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split= 0.1,\n",
    "                    #validation_data=(val_images, val_y)\n",
    "                    verbose=1)\n",
    "\n",
    "results_train = model.evaluate(train_images, train_labels)\n",
    "results_test = model.evaluate(val_images, val_labels)\n",
    "\n",
    "results_train\n",
    "\n",
    "results_test\n",
    "\n",
    "#model.predict_classes(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelvan{}.h5'.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_47_input to have 4 dimensions, but got array with shape (68, 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3b12ab78e90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/aw0520/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aw0520/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aw0520/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aw0520/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_47_input to have 4 dimensions, but got array with shape (68, 11)"
     ]
    }
   ],
   "source": [
    "model.predict_classes(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
