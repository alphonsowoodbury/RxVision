{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "2RxID15_model7-3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x3VOTGc7HCIW",
        "06MOSH_HHCIY",
        "RQCNPDKuUh9p"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-1.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-woodbury/RxVision/blob/master/Notebooks/rxv_model_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kYtcNyOWHCIA"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4put2DlWVPn",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvomtHR2etMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOEEtCT1cxIL",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "import imgaug as ia\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#!{sys.executable} -m pip install opencv-python\n",
        "\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import tensorflow.keras \n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import multiprocessing\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, GridSearchCV, validation_curve \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, r2_score, recall_score, precision_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, validation_curve\n",
        "from sklearn.pipeline import make_pipeline\n",
        "#from tensorflow.keras import get_default_graph\n",
        "\n",
        "from pandas_datareader import data\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import urllib.request, json\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# This code has been tested with TensorFlow 1.6\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "np.random.seed(123)\n",
        "\n",
        "# Transfer learning with VGG16\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "import random \n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWgAgbA4QlgN",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yhhoc-xQlMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_acc_val_plot():\n",
        "  class_size =  int(val_generator.samples / len(val_generator.class_indices))\n",
        "  acc = hist['acc']\n",
        "  val_acc = hist['val_acc']\n",
        "\n",
        "  loss = hist['loss']\n",
        "  val_loss = hist['val_loss']\n",
        "\n",
        "  epochs_range = range(EPOCHS)\n",
        "\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(range(0,len(hist)), acc, label='Training Accuracy')\n",
        "  plt.plot(range(0,len(hist)), val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.plot(range(0,len(hist)), loss, label='Training Loss')\n",
        "  plt.plot(range(0,len(hist)), val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.savefig('{}_AccLoss.png'.format(model.name))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvJ7XkmIQxhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_confusion():\n",
        "  labels = list((val_generator.class_indices).values())\n",
        "  pred = model.predict(val_generator)\n",
        "  y_pred=np.argmax(pred,axis=1)\n",
        "  y_true = val_generator.classes\n",
        "\n",
        "  cf_matrix = metrics.confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(8,6.75))  \n",
        "  pal = sns.light_palette(\"#ffab40\", as_cmap=True)\n",
        "  sns.heatmap(cf_matrix, annot=True,cmap=pal,ax=ax)\n",
        "  plt.ylabel('Class Prediction', fontweight='bold')\n",
        "  plt.xlabel('Class Actual', fontweight='bold')\n",
        "  plt.title('{} Confusion Matrix'.format(model.name), fontweight='bold', loc='left')\n",
        "  #plt.savefig('../Images/{}_conf'.format(model.name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a_n0ELhSKBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_plot():\n",
        "  %cd /content/drive/My Drive/RxID2/Data/Download\n",
        "  dfx = df[df.TYPE == 'MC_COOKED_CALIBRATED_V1.2']\n",
        "  samplesdfx = dfx.groupby(['NDC']).min().reset_index()\n",
        "  sampleslist2 = samplesdfx.FILE.tolist()\n",
        "  #len(sampleslist2)\n",
        "\n",
        "  samplefiles = []\n",
        "  for image in sampleslist2:\n",
        "      smplsplt = image.split('/')\n",
        "      keep = smplsplt[-1]\n",
        "      keep = keep[:-4]\n",
        "      keep= keep +('.JPG')\n",
        "      samplefiles.append(keep)\n",
        "\n",
        "      \n",
        "  #for file in os.listdir():\n",
        "  drgimg = os.listdir()\n",
        "  images = []\n",
        "  for file in samplefiles:\n",
        "      data = plt.imread(file)\n",
        "      images.append(data)\n",
        "  plt.figure(figsize=(15,15))\n",
        "  columns = 5\n",
        "\n",
        "  for i, image in enumerate(images): # iterate through the images in the array 'images'\n",
        "      k = i * class_size\n",
        "      j = (i + 1) * class_size\n",
        "      trues = int(y_true[k:j].mean())\n",
        "      preds = list(y_pred[k:j]).count(trues)\n",
        "      #print(trues,preds)\n",
        "      lst = list(y_pred[k:j])\n",
        "      preddict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0}\n",
        "      for pred in lst:\n",
        "          preddict[pred] +=1\n",
        "      preddict = {k: v for k, v in sorted(preddict.items(), key=lambda item: item[1], reverse=True)}\n",
        "      for k, v in list(preddict.items()):\n",
        "          if v == 0:\n",
        "              del preddict[k]\n",
        "      predlist = list(preddict.keys())\n",
        "      #predmost = list(set(lst))\n",
        "      dname = df.DRUG[df.FILENAME.str.contains(samplefiles[i][:-4])].tolist()[0] # get the drug name from the df for the image in index i \n",
        "      dndc = df.NDC[df.FILENAME.str.contains(samplefiles[i][:-4])].tolist()[0] # get the NDC from the df for the image in index i \n",
        "      title = '[' + str(i) + '] ' + ' ' + dname + '\\nCorrect: ' + str(preds) + '\\nPreds: ' +  ', '.join(map(str,predlist)) # title for each subplot: class, drug name, and NDC\n",
        "      plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "      plt.suptitle('RxID15 Classes',fontweight='bold',fontsize='large', color= '#ffab40')\n",
        "      plt.subplots_adjust(hspace=0.2,wspace=0.25, top=.9, bottom=.2) # i believe this is the subplots spacing from each other and within the plot\n",
        "      #plt.margins(tight=True) # not sure which margins this is impacting\n",
        "      plt.title(title,fontweight='semibold',fontsize='10')\n",
        "      plt.imshow(image)\n",
        "      plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "      #plt.savefig('../../Images/{}_predictions.jpg'.format(model.name),format='jpg',quality=95,dpi=300, bbox='tight',pad_inches = 0) # bbox has always given me the output i wanted...\n",
        "  %cd ../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ncnwmilLHCIG"
      },
      "source": [
        "## Data Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO7w-Uj1cxIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/RxID2/Data/rxid15.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6SL58wXXHCIH",
        "colab": {}
      },
      "source": [
        "data ='/content/drive/My Drive/RxID2/Data/RxID2_split'\n",
        "test_folder = '/content/drive/My Drive/RxID2/Data/RxID2_split/test'\n",
        "train_folder = '/content/drive/My Drive/RxID2/Data/RxID2_split/train'\n",
        "val_folder = '/content/drive/My Drive/RxID2/Data/RxID2_split/validation'\n",
        "realworld_folder = '//content/drive/My Drive/RxID2/Data/RxID2_split/realworld2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vsoYLH3Pjz29"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GS9srx0bkrjf",
        "outputId": "b41face0-a0b5-4191-bf0a-c045b7f96b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SHAPE  = 224 \n",
        "EPOCHS = 150\n",
        "\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_folder,\n",
        "                                                                        shuffle=True,\n",
        "                                                                        target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                        batch_size = BATCH_SIZE) \n",
        "\n",
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_folder,\n",
        "                                                                       shuffle=False,\n",
        "                                                                       class_mode='categorical',\n",
        "                                                                       target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                       batch_size = BATCH_SIZE)\n",
        "realworld_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(realworld_folder,\n",
        "                                                                       shuffle=False,\n",
        "                                                                       class_mode='categorical',\n",
        "                                                                       target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                       batch_size = BATCH_SIZE)\n",
        "\n",
        "train_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                     width_shift_range=(0.5,1.5),\n",
        "                                     height_shift_range=(0.5,1.5),\n",
        "                                     brightness_range=(.25,1.75),\n",
        "                                     shear_range=0.2,\n",
        "                                     #channel_shift_range=128,\n",
        "                                     rotation_range=45,\n",
        "                                     vertical_flip=True,\n",
        "                                     #fill_mode=\"nearest\",\n",
        "                                     zoom_range=0.35).flow_from_directory(train_folder,\n",
        "                                                                          shuffle=True,\n",
        "                                                                          class_mode='categorical',\n",
        "                                                                          target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                          batch_size=BATCH_SIZE)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 71 images belonging to 15 classes.\n",
            "Found 75 images belonging to 15 classes.\n",
            "Found 15 images belonging to 15 classes.\n",
            "Found 300 images belonging to 15 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vaBinm7bmiah"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3qODb2QHGUH",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "[(github)](https://github.com/a-woodbury/RxVision/blob/master/Notebooks/rxv_vgg16_4.ipynb)\n",
        "\n",
        "- blah blah blah \n",
        "- blah blah blah \n",
        "- blah blah blah \n",
        "\n",
        "Selection: [y/n]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6RP-zBnf0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = load_model('/content/drive/My Drive/RxID2/Models/rxv_vgg_1.h5')\n",
        "hist = pd.read_csv('/content/drive/My Drive/RxID2/histmodel7.log', sep=',', engine='python')\n",
        "model2.summary()\n",
        "model2_val_results = model2.evaluate(val_generator)\n",
        "modelacc1 = model2_val_results[1]\n",
        "model2_rw_results = model2.evaluate(realworld_generator)\n",
        "model2rw = model2_rw_results[1]\n",
        "print('\\nValidation Accuracy: ' + str(int(modelacc1*100)) + '\\nReal-world Accuracy: ' + str(int(model2rw*100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH1iVs-nQfj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_acc_val_plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "habcyjT5Q2y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_confusion()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJjktoZqSS3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbk1wNC-T4i1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60003b4b-0834-40eb-f87d-aa132de7d16a"
      },
      "source": [
        "model2.predict_generator(realworld_generator)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2yK-Oi2Tukr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}